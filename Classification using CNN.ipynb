{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using :\n",
    "# no. of fileters = 32\n",
    "# size of each fileter = 3*3\n",
    "# each pool size = 2*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Convolution2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#inputlayer : apply filters\n",
    "model.add(Convolution2D(filters=32, \n",
    "                        kernel_size=(3,3), \n",
    "                        activation='relu',\n",
    "                   input_shape=(64, 64, 3)\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "=================================================================\n",
      "Total params: 896\n",
      "Trainable params: 896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pooling layer where we are doing maxpooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modification for increasing accuracy\n",
    "model.add(Convolution2D(filters=32, \n",
    "                        kernel_size=(3,3), \n",
    "                        activation='relu',\n",
    "                       ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modification for increasing accuracy\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#layer inwhich we areconverting 2d/3d image to 1d image i.e flattening\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "=================================================================\n",
      "Total params: 10,144\n",
      "Trainable params: 10,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer: appling relu to give positive output\n",
    "# from here our hidden layerrs starts\n",
    "model.add(Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "=================================================================\n",
      "Total params: 813,088\n",
      "Trainable params: 813,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer : to provide binary output using sigmoid function\n",
    "model.add(Dense(units=3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               802944    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 813,475\n",
      "Trainable params: 813,475\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 600 images belonging to 3 classes.\n",
      "Found 150 images belonging to 3 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "50/50 [==============================] - 57s 1s/step - loss: 0.0788 - accuracy: 0.9734 - val_loss: 1.4088e-07 - val_accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 50s 1s/step - loss: 1.3560e-06 - accuracy: 1.0000 - val_loss: 5.4457e-07 - val_accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 47s 940ms/step - loss: 9.3588e-07 - accuracy: 1.0000 - val_loss: 2.6280e-07 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 54s 1s/step - loss: 9.3511e-07 - accuracy: 1.0000 - val_loss: 1.2734e-07 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 50s 1s/step - loss: 9.1923e-07 - accuracy: 1.0000 - val_loss: 2.1133e-07 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2b2bc64ecf8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#image augmentation\n",
    "#url : https://keras.io/api/preprocessing/image/ \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "        'Dataset/train/',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "        'Dataset/test/',\n",
    "        target_size=(64,64),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "model.fit(\n",
    "        training_set,\n",
    "        steps_per_epoch=50,\n",
    "        epochs=5,\n",
    "        validation_data=test_set,\n",
    "        validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"new_cnn_model.h5\")   #save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model\n",
    "#model=load_model(\"cnn_model.h5\")  #load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing on a pic that not in training and also not in test set whereas it has not been shown to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.load_img(\"Dataset/sample/e.jpeg\",target_size=(64,64))\n",
    "#test_image = image.load_img(\"C:/Users/ASUS/Desktop/cat.jpg\",target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PIL.Image.Image"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x2B2E4DC55C0>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image #since this format is PIL or pillow so it can be printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = image.img_to_array(test_image)  #convert PIL image to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64, 3)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "#since keras uses tensor flow and for tensorflow it needs 4d image so we converted 3d image to 4d image using above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'down': 0, 'up': 1, 'wait': 2}"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices # to see classes of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to check where this particular image belongs to, so these above values means that 0 represents cat and 1 represents dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait\n"
     ]
    }
   ],
   "source": [
    "if result[0][0]==1:\n",
    "    print(\"Down\")\n",
    "elif result[0][1]==1:\n",
    "    print(\"Up\")\n",
    "else:\n",
    "    print(\"Wait\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model=load_model(\"new_cnn_model.h5\")  #load model\n",
    "import cv2\n",
    "import pyautogui\n",
    "pyautogui.FAILSAFE=False\n",
    "import time \n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "cap = cv2.VideoCapture(0)\n",
    "ans=\"\"\n",
    "\n",
    "#time.sleep(5)\n",
    "start_time=time.time()\n",
    "play=0\n",
    "\n",
    "while True:\n",
    "    ans=\"\"\n",
    "    status , photo = cap.read()\n",
    "    if photo is None:\n",
    "        continue\n",
    "    test_image=photo.copy()\n",
    "    test_image = cv2.resize(test_image,(64,64))\n",
    "    test_image = np.expand_dims(test_image,axis=0)\n",
    "#since keras uses tensor flow and for tensorflow it needs 4d image so we converted 3d image to 4d image using above\n",
    "    result = model.predict(test_image)\n",
    "    if result[0][0]==1:\n",
    "        cv2.putText(photo,\"Down\",(50, 50),cv2.FONT_HERSHEY_SIMPLEX ,1,(255, 0, 0),2,cv2.LINE_AA)\n",
    "        ans=\"down\"\n",
    "        pyautogui.click(1356, 716) \n",
    "    elif result[0][1]==1:\n",
    "        cv2.putText(photo,\"Up\",(50, 50),cv2.FONT_HERSHEY_SIMPLEX ,1,(255, 0, 0),2,cv2.LINE_AA)\n",
    "        ans=\"up\"\n",
    "        pyautogui.click(1356, 210) \n",
    "    elif result[0][2]==1:\n",
    "        cv2.putText(photo,\"wait\",(50, 50),cv2.FONT_HERSHEY_SIMPLEX ,1,(255, 0, 0),2,cv2.LINE_AA)\n",
    "        ans=\"wait\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    cv2.imshow('hi' , photo)\n",
    "    \n",
    "    cur_time=time.time()\n",
    "    timer=cur_time-start_time\n",
    "    if cv2.waitKey(10) == 13 or timer>=60:  #when pressed enter it break loop will close or when timer expires\n",
    "        break\n",
    "    #print(timer)\n",
    "    \n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point(x=1356, y=717)\n"
     ]
    }
   ],
   "source": [
    "import pyautogui \n",
    "print(pyautogui.position()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
